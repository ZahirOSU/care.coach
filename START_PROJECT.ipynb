{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9457507f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from scipy.spatial.distance import cdist   \n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c8071",
   "metadata": {},
   "source": [
    "# Question 1 \n",
    "\n",
    "change the code below to make the data distribution of x closer to this image\n",
    "\n",
    "<img src=\"upperleft.png\" height=500 width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f1149a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 1:\n",
    "\n",
    "pts = 50\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "a = rng.multivariate_normal(\n",
    "    mean=[3,3], \n",
    "    cov=[[1,0],\n",
    "         [0,1]], \n",
    "    size=pts,\n",
    ")\n",
    "\n",
    "b = rng.multivariate_normal(\n",
    "    mean=[0,0], \n",
    "    cov=[[1,0],\n",
    "         [0,1]], \n",
    "    size=pts,\n",
    ")\n",
    "\n",
    "x = np.concatenate((a, b))\n",
    "\n",
    "# Plot data \n",
    "plt.scatter(x[:, 0], x[:, 1])\n",
    "plt.xlabel(\"x0\")\n",
    "plt.ylabel(\"x1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deee5d9",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "Fix the bug in this k-mean clustering function, then plot the resulting color labeled clusters like this\n",
    "\n",
    "<img src=\"Q2.png\" height=500 width=500>\n",
    "\n",
    "and lastly edit the function's docstrings and comments to make the type of input arguments expected more clear as well as the algorithm readable like pseudocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c99d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2:\n",
    "\n",
    "def kmeans(x, k, no_of_iterations):  \n",
    "    \n",
    "    \"\"\" Function to implement k-means clustering \n",
    "    # x is a (num_samples, 2) numpy array \n",
    "    # k is number of clusters \n",
    "    # no_of_iterations is the number of iterations to run k means\n",
    "    \"\"\"\n",
    "    \n",
    "    idx = np.random.choice(len(x), k, replace=False)     \n",
    "    #Randomly choosing Centroids     \n",
    "    \n",
    "    centroids = x[idx, :]       \n",
    "    distances = cdist(x, centroids ,'euclidean')          \n",
    "    points = np.array([np.argmax(i) for i in distances])  \n",
    "    \n",
    "    for _ in range(no_of_iterations):  \n",
    "        \n",
    "        centroids = []      \n",
    "        \n",
    "        for idx in range(k):     \n",
    "            \n",
    "            temp_cent = x[points==idx].mean(axis=1)   \n",
    "            centroids.append(temp_cent) \n",
    "            centroids = np.vstack(centroids)  \n",
    "            distances = cdist(x, centroids ,'euclidean')    \n",
    "            \n",
    "        points = np.array([np.argmax(i) for i in distances])              \n",
    "            \n",
    "    return points\n",
    "\n",
    "points = kmeans(x,k=2,no_of_iterations=10)\n",
    "\n",
    "cluster1 = x[points==0]\n",
    "cluster2 = x[points==1]\n",
    "\n",
    "# Plot data \n",
    "plt.scatter(cluster1[:, 0], cluster1[:, 1])\n",
    "plt.scatter(cluster2[:, 0], cluster2[:, 1])\n",
    "plt.xlabel(\"x0\")\n",
    "plt.ylabel(\"x1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691396e0",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "604d7f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration huggingface-course--codeparrot-ds-train-a9b1bc4c2b855d04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/huggingface-course--codeparrot-ds-train to /Users/carson/.cache/huggingface/datasets/huggingface-course___json/huggingface-course--codeparrot-ds-train-a9b1bc4c2b855d04/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e40d4417c7645fa85f211762bd872ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ba85126bf649adb76b32f5a36826e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49904d384ef4b7aae28cb5d77bab348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /Users/carson/.cache/huggingface/datasets/huggingface-course___json/huggingface-course--codeparrot-ds-train-a9b1bc4c2b855d04/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration huggingface-course--codeparrot-ds-valid-e5ece22bd7b6a6ac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/huggingface-course--codeparrot-ds-valid to /Users/carson/.cache/huggingface/datasets/huggingface-course___json/huggingface-course--codeparrot-ds-valid-e5ece22bd7b6a6ac/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55b91eaae0f4c9086c107fa7eabf268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f942b766388c425f8811df714f408800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/46.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1944a48fbdc04730a4d68622b526ea02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /Users/carson/.cache/huggingface/datasets/huggingface-course___json/huggingface-course--codeparrot-ds-valid-e5ece22bd7b6a6ac/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "ds_train = load_dataset(\"huggingface-course/codeparrot-ds-train\", split=\"train\")\n",
    "ds_valid = load_dataset(\"huggingface-course/codeparrot-ds-valid\", split=\"validation\")\n",
    "\n",
    "raw_datasets = DatasetDict(\n",
    "    {\n",
    "        \"train\": ds_train.shuffle().select(range(50000)),\n",
    "        \"valid\": ds_valid.shuffle().select(range(500))\n",
    "    }\n",
    ")\n",
    "\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ce9e574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['repo_name', 'path', 'copies', 'size', 'content', 'license'])\n",
      " \n",
      "REPO_NAME: dvro/imbalanced-learn\n",
      "PATH: imblearn/under_sampling/tests/test_allknn.py\n",
      "COPIES: 2\n",
      "SIZE: 9960\n",
      "CONTENT: \"\"\"Test the module repeated edited nearest neighbour.\"\"\"\n",
      "from __future__ import print_function\n",
      "\n",
      "import os\n",
      "\n",
      "import numpy as np\n",
      "from numpy.testing import assert_raises\n",
      "from numpy.testing import assert_e\n",
      "LICENSE: mit\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets[\"train\"][0].keys())\n",
    "print(\" \")\n",
    "for key in raw_datasets[\"train\"][0]:\n",
    "    print(f\"{key.upper()}: {raw_datasets['train'][0][key][:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06d9a3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"Test the module repeated edited nearest neighbour.\"\"\"\n",
      "from __future__ import print_function\n",
      "\n",
      "import os\n",
      "\n",
      "import numpy as np\n",
      "from numpy.testing import assert_raises\n",
      "from numpy.testing import assert_e\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets[\"train\"][0][\"content\"][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "767ded2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df9063f6a614446b1d5dc0c51d73557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/265 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39520c2d5a34b5083cc721b3cf2bea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/771k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54b6958b6904b5d8932aca4e2221090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea22c15978c479582c0f4b7544372a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.28M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96dbd9c09bbe4ed0a30f9fdf4f05110f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs length: 46\n",
      "Input chunk lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 25, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 109]\n",
      "Chunk mapping: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "context_length = 128\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"huggingface-course/code-search-net-tokenizer\")\n",
    "\n",
    "outputs = tokenizer(\n",
    "    raw_datasets[\"train\"][:2][\"content\"],\n",
    "    truncation=True,\n",
    "    max_length=context_length,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_length=True,\n",
    ")\n",
    "\n",
    "print(f\"Input IDs length: {len(outputs['input_ids'])}\")\n",
    "print(f\"Input chunk lengths: {(outputs['length'])}\")\n",
    "print(f\"Chunk mapping: {outputs['overflow_to_sample_mapping']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68c562bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs length: 28\n",
      "Input chunk lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 25]\n",
      "Chunk mapping: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "outputs = tokenizer(\n",
    "    raw_datasets[\"train\"][:1][\"content\"],\n",
    "    truncation=True,\n",
    "    max_length=context_length,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_length=True,\n",
    ")\n",
    "\n",
    "print(f\"Input IDs length: {len(outputs['input_ids'])}\")\n",
    "print(f\"Input chunk lengths: {(outputs['length'])}\")\n",
    "print(f\"Chunk mapping: {outputs['overflow_to_sample_mapping']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83fe239a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs length: 68\n",
      "Input chunk lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 25, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 109, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 101]\n",
      "Chunk mapping: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "outputs = tokenizer(\n",
    "    raw_datasets[\"train\"][:3][\"content\"],\n",
    "    truncation=True,\n",
    "    max_length=context_length,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_length=True,\n",
    ")\n",
    "\n",
    "print(f\"Input IDs length: {len(outputs['input_ids'])}\")\n",
    "print(f\"Input chunk lengths: {(outputs['length'])}\")\n",
    "print(f\"Chunk mapping: {outputs['overflow_to_sample_mapping']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4173d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad67a08f49184fb980d25cf1db57c969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e07d9858144dd8a52b2fd3c719510b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 1371130\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 13166\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"content\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize, batched=True, remove_columns=raw_datasets[\"train\"].column_names\n",
    ")\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe0cb0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 124.2M parameters\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=context_length,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(config)\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0dc0c55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([5, 128])\n",
      "attention_mask shape: torch.Size([5, 128])\n",
      "labels shape: torch.Size([5, 128])\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "out = data_collator([tokenized_datasets[\"train\"][i] for i in range(5)])\n",
    "\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16738591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc8e7c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword has not single token: testtest\n"
     ]
    }
   ],
   "source": [
    "keytoken_ids = []\n",
    "for keyword in [\n",
    "    \"plt\",\n",
    "    \"pd\",\n",
    "    \"sk\",\n",
    "    \"fit\",\n",
    "    \"predict\",\n",
    "    \" plt\",\n",
    "    \" pd\",\n",
    "    \" sk\",\n",
    "    \" fit\",\n",
    "    \" predict\",\n",
    "    \"testtest\",\n",
    "]:\n",
    "    ids = tokenizer([keyword]).input_ids[0]\n",
    "    if len(ids) == 1:\n",
    "        keytoken_ids.append(ids[0])\n",
    "    else:\n",
    "        print(f\"Keyword has not single token: {keyword}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4f584c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8436, 4289, 1201, 2770, 5431, 2564, 2604, 2110, 2872, 4969]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keytoken_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb22ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    "\n",
    "\n",
    "def keytoken_weighted_loss(inputs, logits, keytoken_ids, alpha=1.0):\n",
    "    # Shift so that tokens < n predict n\n",
    "    shift_labels = inputs[..., 1:].contiguous()\n",
    "    shift_logits = logits[..., :-1, :].contiguous()\n",
    "    # Calculate per-token loss\n",
    "    loss_fct = CrossEntropyLoss(reduce=False)\n",
    "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    # Resize and average loss per sample\n",
    "    loss_per_sample = loss.view(shift_logits.size(0), shift_logits.size(1)).mean(axis=1)\n",
    "    # Calculate and scale weighting\n",
    "    weights = torch.stack([(inputs == kt).float() for kt in keytoken_ids]).sum(\n",
    "        axis=[0, 2]\n",
    "    )\n",
    "    weights = alpha * (1.0 + weights)\n",
    "    # Calculate weighted average\n",
    "    weighted_loss = (loss_per_sample * weights).mean()\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1da27f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=32, shuffle=True)\n",
    "eval_dataloader = DataLoader(tokenized_datasets[\"valid\"], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72c47010",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 0.1\n",
    "\n",
    "\n",
    "def get_grouped_params(model, no_decay=[\"bias\", \"LayerNorm.weight\"]):\n",
    "    params_with_wd, params_without_wd = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        if any(nd in n for nd in no_decay):\n",
    "            params_without_wd.append(p)\n",
    "        else:\n",
    "            params_with_wd.append(p)\n",
    "    return [\n",
    "        {\"params\": params_with_wd, \"weight_decay\": weight_decay},\n",
    "        {\"params\": params_without_wd, \"weight_decay\": 0.0},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7b61fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch[\"input_ids\"], labels=batch[\"input_ids\"])\n",
    "\n",
    "        losses.append(accelerator.gather(outputs.loss))\n",
    "    loss = torch.mean(torch.cat(losses))\n",
    "    try:\n",
    "        perplexity = torch.exp(loss)\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "    return loss.item(), perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22263784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(get_grouped_params(model), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11d64b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carson/projects/buddy/env_ds/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "/Users/carson/projects/buddy/env_ds/lib/python3.8/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator(fp16=True)\n",
    "\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "281bbc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42848\n",
      "42848\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 1\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "print(num_update_steps_per_epoch)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "print(num_training_steps)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=1_000,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1715bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss, perplexity = evaluate()\n",
    "print(eval_loss, perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "gradient_accumulation_steps = 8\n",
    "eval_steps = 5_000\n",
    "\n",
    "model.train()\n",
    "completed_steps = 0\n",
    "for epoch in range(num_train_epochs):\n",
    "    for step, batch in tqdm(\n",
    "        enumerate(train_dataloader, start=1), total=num_training_steps\n",
    "    ):\n",
    "        logits = model(batch[\"input_ids\"]).logits\n",
    "        loss = keytoken_weighted_loss(batch[\"input_ids\"], logits, keytoken_ids)\n",
    "        if step % 100 == 0:\n",
    "            accelerator.print(\n",
    "                {\n",
    "                    \"lr\": get_lr(),\n",
    "                    \"samples\": step * samples_per_step,\n",
    "                    \"steps\": completed_steps,\n",
    "                    \"loss/train\": loss.item() * gradient_accumulation_steps,\n",
    "                }\n",
    "            )\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        accelerator.backward(loss)\n",
    "        if step % gradient_accumulation_steps == 0:\n",
    "            accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            completed_steps += 1\n",
    "        if (step % (eval_steps * gradient_accumulation_steps)) == 0:\n",
    "            eval_loss, perplexity = evaluate()\n",
    "            accelerator.print({\"loss/eval\": eval_loss, \"perplexity\": perplexity})\n",
    "            model.train()\n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "            if accelerator.is_main_process:\n",
    "                tokenizer.save_pretrained(output_dir)\n",
    "                repo.push_to_hub(\n",
    "                    commit_message=f\"Training in progress step {step}\", blocking=False\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
