{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9457507f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from scipy.spatial.distance import cdist   \n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c8071",
   "metadata": {},
   "source": [
    "Part 1 and 2 are basic data science skills questions, the main project is in the last parts, Part 3 and 4. \n",
    "\n",
    "# Part 1 \n",
    "\n",
    "Change the code below, ie the [variances and covariances](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.multivariate_normal.html), to make the data distribution of x closer to this image:\n",
    "\n",
    "<img src=\"upperleft.png\" height=500 width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f1149a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part 1:\n",
    "\n",
    "# number of samples per cluster\n",
    "pts = 50 \n",
    "\n",
    "# random number generator\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "a = rng.multivariate_normal(\n",
    "    mean=[3,3], \n",
    "    cov=[[1,0],\n",
    "         [0,1]], \n",
    "    size=pts,\n",
    ")\n",
    "\n",
    "b = rng.multivariate_normal(\n",
    "    mean=[0,0], \n",
    "    cov=[[1,0],\n",
    "         [0,1]], \n",
    "    size=pts,\n",
    ")\n",
    "\n",
    "x = np.concatenate((a, b))\n",
    "\n",
    "# Plot data \n",
    "plt.scatter(x[:, 0], x[:, 1])\n",
    "plt.xlabel(\"x0\")\n",
    "plt.ylabel(\"x1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deee5d9",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "Fix the bug in this k-mean clustering function, use it to cluster the combined data `x` (not `a` and `b`) then plot the resulting color labeled clusters like this:\n",
    "\n",
    "<img src=\"Q2.png\" height=500 width=500>\n",
    "\n",
    "Add Comments `#like this ` to show where the changes you made are, and to explain how the function now works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c99d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2:\n",
    "\n",
    "def kmeans(x, k, no_of_iterations):  \n",
    "    \n",
    "    \"\"\" Function to implement k-means clustering \n",
    "    # x is a (num_samples, 2) numpy array \n",
    "    # k is number of clusters \n",
    "    # no_of_iterations is the number of iterations to run k means\n",
    "    \"\"\"\n",
    "    \n",
    "    # Randomly choose initial Centroids \n",
    "    idx = np.random.choice(len(x), k, replace=False)         \n",
    "    \n",
    "    centroids = x[idx, :]       \n",
    "    distances = cdist(x, centroids ,'euclidean')          \n",
    "    points = np.array([np.argmax(i) for i in distances])  \n",
    "    \n",
    "    # main loop\n",
    "    for _ in range(no_of_iterations):  \n",
    "        \n",
    "        centroids = []      \n",
    "        \n",
    "        for idx in range(k):     \n",
    "            \n",
    "            temp_cent = x[points==idx].mean(axis=1)   \n",
    "            centroids.append(temp_cent) \n",
    "            centroids = np.vstack(centroids)  \n",
    "            distances = cdist(x, centroids ,'euclidean')    \n",
    "            \n",
    "        points = np.array([np.argmax(i) for i in distances])              \n",
    "            \n",
    "    return points\n",
    "\n",
    "# use function\n",
    "points = kmeans(x,k=2,no_of_iterations=10)\n",
    "\n",
    "# assign clusters\n",
    "cluster1 = x[points==0]\n",
    "cluster2 = x[points==1]\n",
    "\n",
    "# Plot the data in labeled clusters \n",
    "plt.scatter(cluster1[:, 0], cluster1[:, 1])\n",
    "plt.scatter(cluster2[:, 0], cluster2[:, 1])\n",
    "plt.xlabel(\"x0\")\n",
    "plt.ylabel(\"x1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691396e0",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "\n",
    "## Intro to Part 3\n",
    "\n",
    "We will be retraining the autoregressive large language model GPT2 from this paper [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) to perform some new tasks for us. \n",
    "\n",
    "We have provided some starter code below and in `utils.py` that shows how we can load a pretrained large language model.\n",
    "\n",
    "In `utils.py` you will find a rudimentary class called `BaseAgent` with a class method called `memorize` that can be used to retrain (aka finetune) the model. This is not the best way to finetune, but it can be used as starter code to a new method that can finetune the model. \n",
    "\n",
    "In the cells below, I demonstrate how this class is used to overlearn, aka memorize, one conversational example, aka one sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f181721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.device_count() 2\n",
      "torch.cuda.empty_cache() None\n",
      "4.15.0\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#sys libs\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "\n",
    "#data manupulation libs\n",
    "import numpy as np\n",
    "\n",
    "#string manupulation libs\n",
    "import re\n",
    "import string\n",
    "\n",
    "#torch libs\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "print('torch.cuda.device_count()', torch.cuda.device_count())\n",
    "print('torch.cuda.empty_cache()', torch.cuda.empty_cache())\n",
    "\n",
    "#huggingface transformers\n",
    "import transformers\n",
    "from transformers import set_seed\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "print(transformers.__version__)\n",
    "\n",
    "# Custom Code\n",
    "from utils import BaseAgent\n",
    "\n",
    "# seeds\n",
    "set_seed(42)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "604d7f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_dir= ./modelstates/hugface_models/gpt2\n",
      "model_save_path= ./modelstates/finetuned_models/gpt2\n"
     ]
    }
   ],
   "source": [
    "# download the gpt transformer model and tokenizer\n",
    "\n",
    "pretrained_hf_model = 'gpt2'\n",
    "\n",
    "cache_dir = os.path.join(\n",
    "    \"./modelstates/hugface_models/\",\n",
    "    pretrained_hf_model,\n",
    ")\n",
    "\n",
    "print(\"cache_dir=\", cache_dir)\n",
    "\n",
    "model_save_path = os.path.join(\n",
    "    \"./modelstates/finetuned_models\",\n",
    "    pretrained_hf_model,\n",
    ")\n",
    "\n",
    "print(\"model_save_path=\", model_save_path)\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "    pretrained_hf_model,\n",
    "    pad_token='<|endoftext|>',\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\n",
    "    pretrained_hf_model,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "\n",
    "# place the model and tokenizer into our dialog agent\n",
    "\n",
    "agent = BaseAgent(\n",
    "    tokenizer = tokenizer,\n",
    "    model = model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d73a710c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Hello.\n",
      "B: Hi.\n",
      "A: How was your day?\n",
      "B: I was in the hospital.\n",
      "A: What was your name?\n",
      "B: I was in the hospital.\n",
      "A: What was your name?\n",
      "B: I was in the hospital.\n",
      "A: What was your name?\n",
      "B: I was in the hospital.\n",
      "A: What was your name\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A: Hello.\\nB: Hi.\\nA: How was your day?\\nB: I was in the hospital.\\nA: What was your name?\\nB: I was in the hospital.\\nA: What was your name?\\nB: I was in the hospital.\\nA: What was your name?\\nB: I was in the hospital.\\nA: What was your name'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example of how the pretrained model can extend dialog\n",
    "\n",
    "generated_text = agent.get_response(\n",
    "    prompt = \"A: Hello.\\nB: Hi.\\nA: How was your day?\\nB:\",\n",
    "    max_len = 64\n",
    ")\n",
    "\n",
    "print(generated_text)\n",
    "\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d5dbff",
   "metadata": {},
   "source": [
    "#### Hint:\n",
    "\n",
    "Suppose you want to learn the sequence\n",
    "\n",
    "**all dogs are good boys**\n",
    "\n",
    "and suppose you are using word tokenization instead of subword or byte pair encoding\n",
    "\n",
    "Then the target sequence, aka labels, aka `y`, aka target output would be the source sequence, aka input sequence, aka `x`, just shifted to the right by one position\n",
    "\n",
    "source: **all dogs are good**\n",
    "\n",
    "target: **dogs are good boys**\n",
    "\n",
    "this is why in `memorize` you see thise lines doing the same as above\n",
    "\n",
    "```python\n",
    "        source_ids = prompt_ids[:,:-1]\n",
    "        target_ids = prompt_ids[:,1:]\n",
    "        source_mask = prompt_mask[:,:-1]\n",
    "        target_mask = prompt_mask[:,1:]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c3343f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 2.4595978260040283\n",
      "epoch 1 loss 2.0394985675811768\n",
      "epoch 2 loss 1.7277195453643799\n",
      "epoch 3 loss 1.043565273284912\n",
      "epoch 4 loss 0.9133180379867554\n"
     ]
    }
   ],
   "source": [
    "# an example of how to learn to extend in a directed manner\n",
    "\n",
    "agent.memorize(\n",
    "    \"A: Hello.\\nB: Hi.\\nA: How was your day?\\nB: First, you tell me about your day.\",\n",
    "    num_epochs = 5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "277fb8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Hello.\n",
      "B: Hi.\n",
      "A: How was your day?\n",
      "B: First, you tell me about your day.\n",
      "B: First, you tell me about your day.\n",
      "A: First, you tell me about your day.\n",
      "B: First, you tell me about your day.\n",
      "A: First, you tell me about your day.\n",
      "B: First, you tell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A: Hello.\\nB: Hi.\\nA: How was your day?\\nB: First, you tell me about your day.\\nB: First, you tell me about your day.\\nA: First, you tell me about your day.\\nB: First, you tell me about your day.\\nA: First, you tell me about your day.\\nB: First, you tell'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how did our retraining change the model?\n",
    "\n",
    "generated_text = agent.get_response(\n",
    "    prompt = \"A: Hello.\\nB: Hi.\\nA: How was your day?\\nB:\",\n",
    "    max_len = 64\n",
    ")\n",
    "\n",
    "print(generated_text)\n",
    "\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7712ddfc",
   "metadata": {},
   "source": [
    "## Data for Part 3\n",
    "\n",
    "Next lets introduce you to the dataset you will be using for this project. This is a text dataset with multiple conversations, or dialogs, where one of the individuals is acting very empathetically towards the other, and each dialog is labeled by the emotion in that dialog, ie one of 32 different emotions: \n",
    "\n",
    "```python\n",
    "emotion_list = ['sentimental', 'afraid', 'proud', 'faithful', 'terrified', 'joyful', \n",
    "                'angry', 'sad', 'jealous', 'grateful', 'prepared', 'embarrassed', 'excited', \n",
    "                'annoyed', 'lonely', 'ashamed', 'guilty', 'surprised', 'nostalgic',\n",
    "                'confident', 'furious', 'disappointed', 'caring', 'trusting', 'disgusted', \n",
    "                'anticipating', 'anxious', 'hopeful', 'content', 'impressed', 'apprehensive', \n",
    "                'devastated']\n",
    "\n",
    "len(emotion_list) # 32\n",
    "```\n",
    "here are instructions on how to download and unzip that dataset\n",
    "\n",
    "```console \n",
    "wget https://dl.fbaipublicfiles.com/parlai/empatheticdialogues/empatheticdialogues.tar.gz\n",
    "\n",
    "tar -xvf empatheticdialogues.tar.gz\n",
    "\n",
    "rm empatheticdialogues.tar.gz\n",
    "```\n",
    "\n",
    "The unzipped folder has a training, validation and test set split\n",
    "\n",
    "```\n",
    "os.listdir(path_to_empatheticdialogues)\n",
    "\n",
    "# ['train.csv', 'test.csv', 'valid.csv']\n",
    "```\n",
    "\n",
    "you can load the train dataset like this\n",
    "\n",
    "```python\n",
    "splitname = \"train\"\n",
    "df = open(os.path.join(path_to_empatheticdialogues, f\"{splitname}.csv\")).readlines()\n",
    "print(df[0].strip().split(\",\"))\n",
    "\n",
    "# ['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags']\n",
    "```\n",
    "\n",
    "the emotion is under the `context` column, the topic of the conversation is under the `prompt` column, and each speaker's utterance, aka conversational turn, is under the `utterance` column.\n",
    "\n",
    "```python\n",
    "for i in range(1, len(df)):\n",
    "    \n",
    "    data_line = df[i].strip().split(\",\")\n",
    "    \n",
    "    context = data_line[2]\n",
    "    prompt = data_line[3].replace(\"_comma_\", \",\")\n",
    "    \n",
    "print(prompt, \" <EMOTION_TYPE> \", context, ' <|endoftext|>')\n",
    "\n",
    "# I remember going to the fireworks with my best friend. There was a lot of people, but it only felt like us in the world. <EMOTION_TYPE> sentimental <|endoftext|>\n",
    "```\n",
    "\n",
    "Hint:\n",
    "\n",
    "With some edits to the training data, a autoregressive model can be turned into a sentiment analysis classifier. Instead of predicting a set of logits for your different classes, like a sentiment classifier, or predicting the next token, like an autoregressive model, have the model predict the right tokens to explain to you what class of emotion the preceding text is (which of the 32 emotions in this case) as the last tokens of a sequence. Use special tokens like `<EMOTION_TYPE>` and `<|endoftext|>` to signify the difference between text and special outputs. \n",
    "\n",
    "## Goals for Part 3\n",
    "\n",
    "There are 5 goals for this project:\n",
    "\n",
    "#### 1. Preprocess the data into a training and validation set (no need for a test set for this minimal project). The preprocessed dataset should be preprocessed in such a way that it can be used to retrain the large language model as an autoregressive sentiment classifier. For example, the model will be passed:\n",
    "\n",
    "`I am going on my second date with this guy that seems so far to really connect with me, I want to believe this is, you know, \"the one\".`\n",
    "\n",
    "and the model is expected to complete the sequence:\n",
    "\n",
    "`I am going on my third date with this person that seems, so far, to really connect with me. I want to believe this is ... you know ... \"the one\". <EMOTION_TYPE> hopeful <|endoftext|>`\n",
    "\n",
    "(You do NOT need to use all the data in the data folder for this project, you do not have to use a specific split of the data, just use enough data to accomplish your goals, and set aside the validation set so that it is valid according to the definition of a validation)\n",
    "\n",
    "Feel free to use the starter code, it is written in PyTorch to give you full control of the training, but has some major features missing. For example:\n",
    "\n",
    " a. you would have to edit it to allow different batch sizes. \n",
    " b. it does not keep track of the train and validation losses\n",
    " c. there is no early stopping or model saving built in\n",
    " \n",
    "You dont have to use the starter code, feel free to use the [huggingface functionality](https://huggingface.co/course/chapter7/6?fw=pt)\n",
    "\n",
    "Please make your preprocessing code clean, simple and easy to read and explain. Preferably with examples. \n",
    "\n",
    "#### 2. Answer this question: what is the majority classifier, aka [ZeroR (or Zero Rate)](https://towardsdatascience.com/calculating-a-baseline-accuracy-for-a-classification-model-a4b342ceb88f), accuracy on the validation set that you set aside?\n",
    "\n",
    "explain how you calculated your answer\n",
    "\n",
    "#### 3. Rewrite the `BaseAgents`'s `memorize` method found in `utils.py` to accomplish the goal of retraining the model as a autoregressive sentiment classifier. \n",
    "\n",
    "Add an `evaluator` method that calculates the validation set accuracy, accuracy of predicting the correct emotion. While you are retraining the model, keep track of the validation and training losses for each epoch or each batch, output these 2 arrays of losses for plotting in the next step. Also while you are retraining the model, keep track of the validation and training accuracies for each epoch or each batch, output these 2 arrays of accuracies for plotting in the next step.\n",
    "\n",
    "plot a learning curve that has this general shape for the losses:\n",
    "\n",
    "\n",
    "#### 4. Train the model to become a autoregressive sentiment classifier. Show us the training curve, aka learning curve, plots by displaying it in this notebook.\n",
    "\n",
    "your plots should have this general shape for the losses\n",
    "\n",
    "<img src=\"trainingcurve.png\" height=500 width=500>\n",
    "\n",
    "the accuracy plot should look like the losses plot above, only flipped upside down. \n",
    "\n",
    "#### 5. Show us 4 examples of the model working correctly and 4 examples of the model working incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d9551a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a35b92d",
   "metadata": {},
   "source": [
    "# Question 4 (Optional)\n",
    "\n",
    "This part is optional, there is no need to do it if you run out of time doing Question 1 thru 3. \n",
    "\n",
    "Do something creative and fun with this project and show us. \n",
    "\n",
    "For example: \n",
    "\n",
    "1. retrain the model to be a more empathetic chatbot and let us talk to the chatbot\n",
    "\n",
    "```python\n",
    " while True:\n",
    "    tell_bot = input(\"Human > \")\n",
    "    bot_reply = talk_to_bot(tell_bot)\n",
    "    if (\"bye\" in tell_bot):\n",
    "        print('Bot > '+ bot_reply + '\\n')\n",
    "        break\n",
    "    else:\n",
    "        print('Bot > '+ bot_reply + '\\n') \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```console\n",
    "AI: Hello.\n",
    "Human: Hi.\n",
    "AI: How was your day?\n",
    "Human: I just found out i was rejected from that collage I applied to.\n",
    "AI: Im sorry to hear that, was it one you were really needed to get into?\n",
    "Human: no, it just hurts my ego.\n",
    "AI: i also am sad when rejected. the right one for you though is one that will accept you.\n",
    "Human: what emotion am i feeling?\n",
    "AI: disappointed\n",
    "```\n",
    "\n",
    "2. deploy the chatbot to an API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb60c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9daed14c",
   "metadata": {},
   "source": [
    "# Tips\n",
    "\n",
    "1. put most of your work in `utils.py` and use this notebook for demonstration purposes\n",
    "2. for important parts of the code, write the code intuitively (reads easily, self-explanatory), with good documentations a comments, see `cross_entropy_loss` in utils.py\n",
    "3. extra points if the notebook is clean and easy to follow along with even without you presenting it\n",
    "4. you dont have to train on all the data or use this large of a model if you dont have the compute resources, although [google colab](https://colab.research.google.com/) has free GPUs and this model and data will fit onto a colab notebook just fine. What you do need to be able to do is to explain how you preprocessed the data for training and how you trained the model to produce the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb532f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
